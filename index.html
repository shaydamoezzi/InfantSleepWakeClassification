<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Classification of Infant Sleep–Wake States from
    Natural Overnight In-Crib Sleep Videos</title>
  <link rel="icon" type="image/x-icon" href="static/images/northeastern-logo.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <!-- ACLab Banner -->
  <section class="hero" style="background-color: rgb(176, 35, 24); padding: 1rem 0;">
    <div class="hero-body" style="padding: 1rem 1.5rem;">
      <div class="container">
        <div class="columns is-centered is-vcentered">
          <div class="column is-half has-text-centered">
            <img src="static/images/aclab.png" alt="ACLab Logo" style="max-height: 120px;">
          </div>
        </div>
        <div class="columns is-centered">
          <div class="column is-three-quarters has-text-centered">
            <h1 class="title is-2 has-text-white" style="color: white !important; margin-bottom: 2.5rem; font-weight: 600;">Classification of Infant Sleep–Wake States from
              Natural Overnight In-Crib Sleep Videos</h1>
            <p class="subtitle is-4 has-text-white" style="color: white !important; margin-bottom: 1rem;">Shayda Moezzi and ACLab Associates</p>
            
            <div class="publication-links" style="margin-top: 1.5rem;">
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/content/WACV2025W/CV4Small/papers/Moezzi_Classification_of_Infant_Sleep-Wake_States_from_Natural_Overnight_In-Crib_Sleep_WACVW_2025_paper.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-light">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/ostadabbas/Infant-Sleep-vs-Awake-Detection" target="_blank"
                class="external-link button is-normal is-rounded is-light">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Infant sleep is critical for healthy development, and disruptions in sleep patterns can have profound implications
for infant brain maturation and overall well-being. Traditional methods for monitoring infant sleep often rely on
intrusive equipment or time-intensive manual annotations,
which hinder their scalability in clinical and research applications. We present our dataset, SmallSleeps, which
includes 152 hours of overnight recordings of 17 infants
aged 4–11 months captured in real-world home environments. Using this dataset, we train a deep learning algorithm for classification of infant sleep–wake states from
short 90 s video clips drawn from natural, overnight, in-crib
baby monitor footage, based on a two-stream spatiotemporal model which integrates rich RGB frames with optical flow features. Our binary classification algorithm was
trained and tested on "pure" state clips featuring a single
state dominating the timeline (i.e., over 90% sleep or over
90% wake) and achieves over 80% precision and recall. We
also perform a careful experimental study of the result of
training and testing on "mixed" clips featuring specified
levels of heterogeneity, with a view towards applications to
infant sleep segmentation and sleep quality classification
in longer, overnight videos, where local behavior is often
mixed. This local-to-global approach allows for deep learning to be effectively deployed on the strength of tens of thousands of video clips, despite a relatively modest sample size 
of 17 infants.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Main image -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Overall Pipeline</h2>
            <img src="static/images/infantsleepwake-pipeline.png" alt="Infant Sleep-Wake Classification Overview">
            <h2 class="subtitle has-text-centered">
              Architecture of our two-stream network for infant sleep–wake classification. The model processes 90-second video clips through
              parallel RGB and optical flow streams. Each stream consists of: (1) a Feature Extractor using 3D ConvNet to extract spatiotemporal
              features from K sequential frames, (2) a Classifier incorporating self-attention mechanisms for temporal dependency modeling, temporal
              averaging, and fully connected layers with rectified linear unit (ReLU) activation. A modality selection/fusion module allows flexible
              stream combination (RGB alone, flow alone, or RGB + flow) before final classification into Sleep/Wake states. The architecture highlights
              two main processing stages: feature extraction (green blocks) and classification (purple blocks).
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End main image -->

  <!-- SmallSleeps Dataset Section -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3 has-text-centered animate__animated animate__fadeIn">SmallSleeps Dataset Creation</h2>
            <div class="content has-text-justified animate__animated animate__fadeIn animate__delay-1s">
              <p>
              The SmallSleeps dataset represents a significant contribution to infant sleep research, 
              comprising 152 hours of overnight video recordings from 17 infants aged 4-11 months 
              captured in real-world home environments. Unlike traditional sleep studies that rely on
               intrusive equipment, SmallSleeps uses non-invasive video monitoring installed in cribs 
               by caregivers. The dataset features comprehensive behavioral coding performed by research assistants who 
               annotated sleep-wake states based on visible behavioral cues, with a particular focus on 
               arousal events characterized by eye opening and body movements. For our final dataset, the videos were segmented into 90-second clips with varying levels
                of "purity" (percentage of time in a single state), creating a robust foundation for
                 developing and evaluating automated sleep classification algorithms despite the 
                 relatively modest sample size.
              </p>
            </div>
            <div class="columns is-centered animate__animated animate__fadeIn animate__delay-2s">
              <div class="column is-half">
                <img src="static/images/smallsleeps.png" alt="SmallSleeps Dataset Creation Process" class="dataset-image">
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End SmallSleeps Dataset Section -->

  <!-- Purity Bins Section -->
  <section class="hero is-small is-primary">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <div class="title-box animate__animated animate__fadeIn">
              <h2 class="title is-3 has-text-centered">Purity Bins: Capturing the Complexity of Infant Sleep Transitions</h2>
            </div>
            <div class="content-box animate__animated animate__fadeIn animate__delay-1s">
              <p>
                The creation of different "purity bins" in the SmallSleeps dataset addresses a fundamental challenge in infant sleep classification: the natural heterogeneity of sleep-wake transitions. Rather than simplistically categorizing video clips as either "sleep" or "wake," we recognized that real-world infant sleep patterns frequently involve mixed states and gradual transitions. By introducing five threshold bins (90-100%, 80-90%, 70-80%, 60-70%, and 50-60%), each representing the percentage of time an infant spends in a particular state within a 90-second clip, the dataset provides a more nuanced foundation for algorithm development.
              </p>
              <p>
                This stratified approach serves multiple purposes. First, it allows us to train models on "pure" state clips (90-100% in one state) to establish clear baseline performance. Second, it enables systematic evaluation of how algorithm performance degrades when faced with increasingly mixed state clips—a critical consideration for real-world deployment. Finally, this methodology creates a pathway toward more sophisticated sleep segmentation in longer videos, where local behavior often contains mixed states. The paper specifically highlights how the "Pure-State Model" (trained on 90-100% purity clips) and "Mixed-State Model" (trained on 70-100% purity clips) demonstrate different capabilities in handling sleep-wake classification across varying levels of state heterogeneity.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End Purity Bins Section -->

  <!-- Video carousel -->
  <section class="hero is-small is-info">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-three-quarters">
            <div class="content-box">
              <div id="video-carousel" class="carousel results-carousel" style="max-width: 1200px; margin: 0 auto;">
                <div class="item">
                  <video poster="" id="video1" autoplay controls muted loop height="100%" style="max-height: 1000px;">
                    <source src="static/videos/wake_samples_7080.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" id="video2" autoplay controls muted loop height="100%" style="max-height: 1000px;">
                    <source src="static/videos/wake_samples_8090.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" id="video3" autoplay controls muted loop height="100%" style="max-height: 1000px;">
                    <source src="static/videos/wake_samples_90100.mp4" type="video/mp4">
                  </video>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Results Section -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3 has-text-centered">Results and Analysis</h2>
            
            <!-- Results Image -->
            <div class="columns is-centered">
              <div class="column is-full">
                <img src="static/images/results.png" alt="Classification Results Analysis" class="results-image" style="width: 100%; max-width: 1200px; margin: 0 auto; display: block;">
              </div>
            </div>

            <!-- Analysis Paragraphs -->
            <div class="content has-text-justified">
              <p>
                In our analysis of feature performance, we found compelling evidence for the superiority of optical flow features compared to RGB features for infant sleep-wake classification. Our RGB-only models achieved moderate accuracy (71-72%), while models incorporating optical flow features demonstrated substantial improvements, reaching 78% accuracy. The most dramatic enhancement was in recall, which increased by 11-12 percentage points when optical flow was included, while maintaining or slightly improving precision.
                </p>
                
                <p>
                The benefits of optical flow were particularly pronounced in the challenging 70-80% purity bin, where recall improved by 18 points and precision by 3 points compared to RGB-only models. This suggests optical flow excels at capturing the subtle movements characteristic of wake states, especially in ambiguous mixed-state clips. Our t-SNE visualization further supported this finding, showing distinct subject-specific clusters for wake states in the optical flow feature space, while RGB features showed considerable overlap between sleep and wake states within each subject's cluster.
             </p>

           </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End Results Section -->

  <!-- Additional Results Image Section -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3 has-text-centered animate__animated animate__fadeIn">Feature Space Analysis</h2>
            
            <!-- Additional Results Image -->
            <div class="columns is-centered animate__animated animate__fadeIn animate__delay-0.5s">
              <div class="column is-three-quarters">
                <img src="static/images/tsne.png" alt="Feature Space Analysis" class="results-image animate__animated animate__fadeIn animate__delay-1s" style="width: 100%; max-width: 900px; margin: 0 auto; display: block;">
              </div>
            </div>

            <!-- Analysis Paragraph -->
            <div class="content has-text-justified animate__animated animate__fadeIn animate__delay-1.5s">
              <p>
                Our t-SNE visualization of the feature space reveals distinct patterns in how RGB and optical flow features capture sleep-wake states. The optical flow feature space shows clear separation between sleep and wake states, with subject-specific clusters that maintain their distinctiveness. This visualization helps explain the superior performance of optical flow features in our classification tasks, particularly in capturing the subtle movement patterns that distinguish wake states from sleep.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End Additional Results Image Section -->

  <!-- Presentation Recording Section -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-three-quarters">
            <div class="content-box">
              <h2 class="title is-3 has-text-centered">CV4Smalls 2025 Presentation</h2>
              <div class="video-container" style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
                <video 
                  controls 
                  style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                  <source src="static/videos/WACVW_Presentation.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End Presentation Recording Section -->

  <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@InProceedings{Moezzi_2025_WACV,
    author    = {Moezzi, Shayda and Wan, Michael and Manne, Sai Kumar Reddy and Mathew, Amal and Zhu, Shaotong and Galoaa, Bishoy and Hatamimajoumerd, Elaheh and Grace, Emma and Rowan, Cassandra B and Zimmerman, Emily and Taylor, Briana J and Hayes, Marie J and Ostadabbas, Sarah},
    title     = {Classification of Infant Sleep-Wake States from Natural Overnight In-Crib Sleep Videos},
    booktitle = {Proceedings of the Winter Conference on Applications of Computer Vision (WACV) Workshops},
    month     = {February},
    year      = {2025},
    pages     = {42-51}
}</code></pre>
      </div>
  </section>
  <!--End BibTex citation -->

  <!-- Footer -->
  <footer class="footer" style="background-color: black; padding: 3rem 0;">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-half has-text-centered">
          <img src="static/images/nulogo_combined.png" alt="Northeastern University Logo" style="max-height: 80px;">
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
